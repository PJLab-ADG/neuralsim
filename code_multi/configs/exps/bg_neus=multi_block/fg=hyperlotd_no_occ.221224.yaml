Experiment explain:
- Last update: 2022.12.24
- Representation:
  - rigid fg with gtbox = hypernetwork lotd neus
    - preload ckpt trained from nerualgen (2022.11.22)
  - bg = multi-block (aka. forest) neus
- Used information:
  - with_gtbox = True
  - with_mask = True
  - with_lidar = True

#------------------------------------------------------------
#------------    Some shortcut configs
#------------------------------------------------------------

device_ids: -1

near: 0.05
far: 300.0

coarse_step_size: 6.0 # 1.5 Typical value: (far-near) / 40
step_size: 0.15 # 0.02 # Typical value: (far-near) / 4000
num_iters: 30000
extend_size: 60.0

upsample_inv_s: 64.0
num_rays_pixel: 8192
num_rays_lidar: 8192

radius_scale_min: 1 # Nearest sampling shell of NeRF++ background (Distant-view model)
radius_scale_max: 1000 # Furthest sampling shell of NeRF++ background (Distant-view model)
distant_interval_type: inverse_proportional
distant_mode: fixed_cuboid_shells
distant_nsample: 64

w_eikonal: 0.001
w_mask: 0.25
a_eikonal_on_render: 0.2
w_sparsity: 3.0e-3
min_factor: 0.2
occ_thre: 0.3
occ_inv_s: 256.0
occ_iter: 16
warmup_steps: 1000
image_embedding_dim: 4

camera_list: [camera_FRONT_LEFT, camera_FRONT, camera_FRONT_RIGHT]
# camera_list: [camera_SIDE_LEFT, camera_FRONT_LEFT, camera_FRONT, camera_FRONT_RIGHT, camera_SIDE_RIGHT]
lidar_list: [lidar_TOP, lidar_FRONT, lidar_REAR, lidar_SIDE_LEFT, lidar_SIDE_RIGHT]
lidar_weight: [0.4,0.1,0.1,0.1,0.1] # Will be normalized when using

exp_dir: ./logs/neuralsim.multi_block/exp_multi_waymo_seg767010_ext${extend_size}_lidarhalf_float_lotforestv3_30k_fix3

dataset_cfg: 
  target: dataio.autonomous_driving.WaymoDataset
  param:
    # root: /data1/waymo/processed/
    root: /nvme/guojianfei/waymo/processed/
    # root: /home/ventus/datasets/waymo/processed1/
    rgb_dirname: images
    lidar_dirname: lidars
    mask_dirname: masks

scenebank_cfg:
  # NOTE: scene_id[,start_frame[,n_frames]]
  scenarios:
    - segment-7670103006580549715_360_000_380_000_with_camera_labels, 15
  observer_cfgs: 
    Camera:
      list: ${camera_list}
    RaysLidar:
      list: ${lidar_list}
  object_cfgs:
    Vehicle:
      dynamic_only: true
  load_class_names: [Street, Vehicle]
  no_objects: false # Set to true to skip loading foreground objects into scene graph
  align_orientation: false
  consider_distortion: true
  scene_graph_has_ego_car: true

assetbank_cfg:
  Street:
    model_class: app.models.large.LoTDForestNeuSStreet
    model_params:
      dtype: half
      var_ctrl_cfg:
        ln_inv_s_init: 0.3
        ln_inv_s_factor: 10.0
      cos_anneal_cfg: null
      surface_cfg:
        # clip_level_grad_ema_factor: 2.0
        encoding_cfg:
          lotd_cfg:
            #------------- LoT v3
            lod_res:     [16,    32,    64,    128, 256]
            lod_n_feats: [8,     4,     2,     8,   4]
            lod_types:   [Dense, Dense, Dense, VM,  VM]
            #------------- hash v4.2
            # lod_res:     [20, 29, 40, 55, 76, 105, 146, 202, 279, 385, 533, 737, 1018]
            # lod_n_feats: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
            # lod_types:   ['Dense', 'Dense', 'Hash', 'Hash', 'Hash', 'Hash', 'Hash', 'Hash', 'Hash', 'Hash', 'Hash', 'Hash', 'Hash']
            # hashmap_size: 65536
          param_init_cfg:
            type: uniform_to_type
            bound: 1.0e-4
        decoder_cfg: 
          # type: linear
          type: mlp
          D: 1
          W: 64
        n_extra_feat_from_output: 0
        radius_init: 0.5
        geo_init_method: pretrain
      radiance_cfg:
        use_pos: true
        use_view_dirs: true
        dir_embed_cfg: 
          type: spherical
          degree: 4
        D: 2
        W: 64
        n_appear_embedding: ${image_embedding_dim}
      use_tcnn_backend: false
      accel_cfg:
        type: occ_grid_forest
        resolution: [16,16,16]
        occ_val_fn_cfg:
          type: sdf
          # inv_s: 64.0 # ~> +- 0.1 sdf @ 0.01 thre;  +- 0.027 sdf @ 0.5 thre
          inv_s: ${occ_inv_s}
        occ_thre: ${occ_thre}
        ema_decay: 0.95
        init_cfg:
          mode: from_net
          num_steps: 4
          num_pts: ${eval:"2**22"}
        update_from_net_cfg:
          num_steps: 4
          num_pts: ${eval:"2**22"}
        update_from_samples_cfg: {}
        n_steps_between_update: 16
        n_steps_warmup: 256
      ray_query_cfg:
        # query_mode: inblock_march_occ_multi_upsample
        query_mode: inblock_march_occ_multi_upsample_compressed
        query_param:
          nablas_has_grad: true
          should_sample_coarse: true
          coarse_step_cfg:
            step_mode: linear
            step_size: ${coarse_step_size} # Typical value: (far-near) / 40
          march_cfg:
            step_size: ${step_size} # Typical value: (far-near) / 4000
            max_steps: 8192
          num_fine: 8
          upsample_inv_s: ${upsample_inv_s}
          upsample_inv_s_factors: [1, 4, 16]
    asset_params:
      initialize_cfg: 
        target_shape: road_surface
        lr: 1.0e-3
        num_iters: 2000
        num_samples: 300000
        w_eikonal: 3.0e-3
        floor_dim: z
        floor_up_sign: 1
        ego_height: 0.5
      populate_cfg: 
        mode: inside_frustum
        extend_size: ${extend_size}
        block_cfgs:
          split_level: 3
          should_force_to_power_of_two: true
          overlap: 0
      training_cfg:
        lr: 1.0e-2
        eps: 1.0e-15
        betas: [0.9, 0.99]
        invs_betas: [0.9, 0.999]
        scheduler: ${training.scheduler}
  Distant:
    model_class: app.models.single.LoTDNeRFDistant
    model_params:
      dtype: half
      encoding_cfg:
        input_ch: 4
        lotd_use_cuboid: true
        lotd_auto_compute_cfg:
          type: ngp4d
          target_num_params: ${eval:"16*(2**20)"} # 16 Mi params
          min_res_xyz: 16
          min_res_w: 4
          n_feats: 2
          log2_hashmap_size: 19
          per_level_scale: 1.382
        param_init_cfg:
          type: uniform_to_type
          bound: 1.0e-4
        # anneal_cfg:
        #   type: hardmask
        #   start_it: ${start_it}
        #   start_level: ${bg_start_level} # (need to be small: so the training is stable; not too small, so there's still valid initialize pretraining.)
        #   stop_it: ${stop_it} # Not for too much iters; should end very soon to not hinder quality
      extra_pos_embed_cfg:
        type: identity
      density_decoder_cfg: 
        type: mlp
        D: 1
        W: 64
        output_activation: softplus
      radiance_decoder_cfg:
        use_pos: false
        # pos_embed_cfg:
        #   type: identity
        use_view_dirs: false
        # dir_embed_cfg:
        #   type: spherical
        #   degree: 4
        use_nablas: false
        D: 2
        W: 64
        n_appear_embedding: ${image_embedding_dim}
      n_extra_feat_from_output: 0
      use_tcnn_backend: false
      include_inf_distance: false # !!! has sky
      radius_scale_min: ${radius_scale_min}
      radius_scale_max: ${radius_scale_max}
      ray_query_cfg:
        query_mode: march
        query_param:
          march_cfg:
            interval_type: ${distant_interval_type}
            sample_mode: ${distant_mode}
            max_steps: ${distant_nsample}
    asset_params:
      populate_cfg:
        cr_obj_classname: Street
      training_cfg:
        lr: 1.0e-2
        eps: 1.0e-15
        betas: [0.9, 0.99]
        scheduler: ${training.scheduler}
  Sky:
    model_class: app.models.env.SimpleSky
    model_params: 
      dir_embed_cfg:
        type: sinusoidal
        n_frequencies: 10
        use_tcnn_backend: false
      D: 2
      W: 256
      use_tcnn_backend: false
      n_appear_embedding: ${image_embedding_dim}
    asset_params:
      training_cfg:
        lr: 1.0e-3
        scheduler: ${training.scheduler}
  Vehicle:
    model_class: app.models.shared.AD_StyleLoTDNeuS
    model_params:
      latents_cfg:
        z_ins: 128
      dtype: half
      var_ctrl_cfg:
        ln_inv_s_init: 0.3
        ln_inv_s_factor: 10.0
      surface_cfg:
        bounding_size: 1.4
        extra_pos_embed_cfg:
          type: sinusoidal_legacy
          n_frequencies: 6
        lotd_grower_cfg: 
          target: nr3d_lib.models.grid_encodings.lotd.lotd_batched_growers.MixedLoTDGrower
          param:
            grower_configs:
              - target: nr3d_lib.models.grid_encodings.lotd.lotd_batched_growers.DenseLoTDGrowerFMM
                param:
                  z_dim: ${assetbank_cfg.Vehicle.model_params.latents.z.dim}
                  lod_res: [5,8,13,21]
                  lod_n_feats: 4
                  pseudo_net_type: same
                  pseudo_net_param:
                    activation: relu
                    fmm_rank: 10
                    equal_lr: false
                    D: 5
                    W: 128
                    embed_cfg:
                      type: sinusoidal_legacy
                      n_frequencies: 6
              - target: nr3d_lib.models.grid_encodings.lotd.lotd_batched_growers.VMSplitLoTDGrowerFMM
                param:
                  z_dim: ${assetbank_cfg.Vehicle.model_params.latents.z.dim}
                  lod_res: [34,55,89,144]
                  lod_n_feats: 4
                  pseudo_net_type: shared
                  pseudo_net_param:
                    activation: relu
                    fmm_rank: 10
                    equal_lr: false
                    D: 4
                    D_head: 2
                    W: 256
                    embed_cfg:
                      type: sinusoidal_legacy
                      n_frequencies: 10
        decoder_cfg:
          D: 2
          W: 64
          activation: relu
      radiance_cfg:
        pos_embed_cfg:
          type: identity
        use_view_dirs: true
        dir_embed_cfg:
          type: spherical
          degree: 4
        D: 2
        W: 64
        skips: []
      accel_cfg:
        type: occ_grid_batched
        resolution: [32,32,32]
        occ_val_fn_cfg:
          type: sdf
          inv_s: ${occ_inv_s}
        occ_thre: ${occ_thre}
        num_steps: ${occ_iter}
        num_pts: ${eval:"2**20"}
      ray_query_cfg:
        query_mode: march_occ_multi_upsample_compressed
        query_param:
          nablas_has_grad: true
          num_coarse: 32
          num_fine: 8
          upsample_inv_s: 64.0
          upsample_inv_s_factors: [1, 4]
          coarse_step_cfg:
            step_mode: linear
          march_cfg:
            step_size: 0.05
            max_steps: 256
    asset_params:
      preload_cfg:
        # load_pt: https://longtimenohack.com/hosted/neuralgen/ckpts/fmm_220626.pt
        load_pt: https://longtimenohack.com/hosted/neuralgen/trained_models/stylelotd_fmm_accel_20221122/ckpts/final_00050000.pt
        use_neuralgen_latents: false
        zero_init_latents: true
  ImageEmbeddings:
    model_class: app.models.scene.ImageEmbeddings
    model_params:
      dims: ${image_embedding_dim}
      weight_init: uniform
      weight_init_std: 1.0e-4
    asset_params:
      training_cfg:
        lr: 2.0e-2
        scheduler: ${training.scheduler}
  #--- Pose refine related
  LearnableParams:
    model_class: app.models.scene.LearnableParams
    model_params:
      refine_ego_motion:
        # node_id: ego_car
        class_name: Camera
      refine_other_motion: 
        class_name: [ Vehicle ]
      refine_camera_intr: null
      refine_camera_extr: null
      enable_after: 500
    asset_params:
      training_cfg:
        ego_motion:
          lr: 0.001
          alpha_lr_rotation: 0.05
        other_motion:
          lr: ${veh_refine_lr}
          alpha_lr_rotation: 0.05
        scheduler: ${training.scheduler}

renderer:
  common:
    with_env: true # !!! has sky
    with_rgb: true
    with_normal: true
    near: ${near} # NOTE: Critical to scene scale!
    far: ${far}
  train:
    depth_use_normalized_vw: false # For meaningful depth supervision (if any)
    perturb: true
  val:
    depth_use_normalized_vw: true # For correct depth rendering
    perturb: false
    rayschunk: 4096

training:
  #---------- Dataset and sampling
  dataloader:
    preload: true
    preload_on_gpu: false
    tags:
      camera:
        downscale: 1
        list: ${camera_list}
      image_occupancy_mask: {}
      image_human_mask: {}
      image_ignore_mask:
        ignore_not_occupied: false
        ignore_dynamic: false
        ignore_human: true
      lidar:
        list: ${lidar_list}
        multi_lidar_merge: true
        filter_when_preload: false # Significantly slows up preload if true
        filter_kwargs:
          filter_in_cams: true
          filter_out_objs: false # !!! We want this
          filter_valid: true
    pixel_dataset:
      #---------- Frame and pixel dataloader
      # joint: false
      # equal_mode: ray_batch
      # num_rays: ${num_rays_pixel}
      # frame_sample_mode: uniform
      # pixel_sample_mode: error_map

      #---------- Joint frame-pixel dataloader
      joint: true
      equal_mode: ray_batch
      num_rays: ${num_rays_pixel}
    lidar_dataset:
      equal_mode: ray_batch
      num_rays: ${num_rays_lidar}
      frame_sample_mode: uniform
      lidar_sample_mode: merged_weighted
      multi_lidar_weight: ${lidar_weight} # Will be normalized when used
  val_dataloader:
    preload: false
    tags:
      camera:
        downscale: 4
        list: ${camera_list}
      image_occupancy_mask: {}
      image_human_mask: {}
      image_ignore_mask:
        ignore_not_occupied: false
        ignore_dynamic: false
        ignore_human: true
    image_dataset:
      camera_sample_mode: uniform
      frame_sample_mode: uniform

  error_map:
    error_map_hw: [32,64]
    frac_uniform: ${eval:"0.5-${ped_errmap_focus}"}
    frac_on_classnames: ${ped_errmap_focus}
    on_classnames: [ Pedestrian, Cyclist ]
    frac_mask_err: 0
    n_steps_max: 500 # NOTE: The actual effective time of this number now needs to be multiplied by the number of cameras! (Because each iteration samples a camera uniformly at random)


  #---------- Training losses
  uniform_sample: 
    Street: ${eval:"2**16"} # 64 Ki

  losses:
    rgb:
      fn_type: mse
      respect_ignore_mask: true
    occupancy_mask:
      w: ${w_mask}
      safe_bce: true
      pred_clip: 0
    lidar:
      discard_outliers: 0
      discard_outliers_median: 100.0
      discard_toofar: 80.0
      depth: 
        w: 0.05
        fn_type: l1_log
    eikonal:
      safe_mse: ${safe_mse}
      safe_mse_err_limit: ${errlim}
      alpha_reg_zero: 0
      on_occ_ratio: ${on_occ_ratio}
      on_render_type: ${on_render_type}
      on_render_ratio: ${on_render_ratio}
      class_name_cfgs:
        Street:
          w: ${w_eikonal}
        Vehicle:
          w: ${veh_wei}
          on_occ_ratio: 0
          on_render_ratio: ${veh_wei_on_render_ratio}
    sparsity:
      class_name_cfgs:
        Street:
          key: sdf
          w: ${w_sparsity} # 1.0e-3
          # anneal: 
          #   type: milestones
          #   milestones:
          #     - ${eval:"${training.num_iters}/3*2"}
          #     - ${training.num_iters}
          #   vals:
          #     - ${w_sparsity}
          #     - ${eval:"${w_sparsity}/10."}
      fn_type: normalized_logistic_density
      fn_param: 
        inv_scale: 16.0
    clearance:
      class_name_cfgs:
        Street:
          w: 2.0
        Vehicle:
          w: 2.0
    weight_reg:
      class_name_cfgs:
        Street:
          norm_type: 2.0
          w: 1.0e-6
        Distant:
          norm_type: 2.0
          w: 1.0e-6

  #---------- Optimization and shedulers
  enable_grad_scaler: true
  num_iters: ${num_iters}
  scheduler:
    #---------- exponential
    type: exponential
    total_steps: ${training.num_iters}
    warmup_steps: ${warmup_steps}
    decay_target_factor: ${min_factor}
    #---------- cosine
    # type: warmup_cosine
    # total_steps: ${training.num_iters}
    # warmup_steps: ${warmup_steps}
    # decay_target_factor: ${min_factor}
    #---------- milestone
    # type: multistep
    # milestones: [20000, 30000]
    # gamma: 0.33

  #---------- Logging and validation
  i_val: 500      # unit: iters
  i_backup: -1 # unit: iters
  i_save: 900     # unit: seconds
  i_log: 20
  log_grad: false
  log_param: false

  ckpt_file: null
  ckpt_ignore_keys: []
  ckpt_only_use_keys: null