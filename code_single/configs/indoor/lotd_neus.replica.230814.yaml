#------------------------------------------------------------
#------------    Some shortcut configs
#------------------------------------------------------------

num_rays: 4096

near: 0.01 # > 0 to avoid potential near artifacts
far: null # Far is already constraint by Object's bounding_size when ray_test()
depth_max: 2.0 # To visualize / colorize depth
bounding_size: 2.0
# bounding_size: 3.0
# step_size: 0.001 # Typical value: far / 4000 for single scene
step_size: 0.005 # Typical value: far / 4000 for single scene
num_coarse: 64
upsample_inv_s: 64.0
# upsample_inv_s_factors: [1, 4]
upsample_inv_s_factors: [1, 4, 16]
num_fine: [8, 8, 32]

rgb_fn_type: mse

w_mask: 0.03

w_mono_normal_l1: 0.01
w_mono_normal_cos: 0.01

mono_fn: mse
mono_w: 1.0e-3
mono_w_reg: 1.0e-5
mono_after: 1500
mono_erode: 8

w_eikonal: 1.0e-3
on_occ_ratio: 1.0
on_render_type: both
on_render_ratio: 1.0

w_sparsity: 1.0e-3
sparsity_enable_after: 0

min_factor: 0.06
fglr: 1.0e-2
emblr: 2.0e-2

num_iters: 7500
image_embedding_dim: 4

warmup_steps: 1000
radius_init: 0.5
start_it: 0
start_level: 2
stop_it: 1000

final_inv_s: 1200.0
ln_inv_s_init: 0.1
ctrl_start_it: 2000

#------------------------------------------------------------
#------------    Full configs
#------------------------------------------------------------
exp_dir: ./logs/replica/instant_neus.${scan_id}

dataset_id: replica
scan_id: scan1
dataset_cfg:
  target: dataio.monosdf.MonoSDFDataset
  param:
    root: /data2/monosdf/data/Replica
    scan_id: ${scan_id}
    dataset_id: ${dataset_id}
    center_crop_type: center_crop_for_replica

scenebank_cfg:
  scenarios:
    - ${scan_id}
  observer_cfgs: 
    Camera:
      list: [camera]

assetbank_cfg:
  Main:
    model_class: app.models.single.LoTDNeuSObj
    model_params:
      dtype: half
      var_ctrl_cfg:
        ln_inv_s_init: ${ln_inv_s_init}
        ln_inv_s_factor: 10.0
        ctrl_type: mix_linear
        start_it: ${ctrl_start_it}
        stop_it: ${training.num_iters}
        final_inv_s: ${final_inv_s}
      cos_anneal_cfg: null
      use_tcnn_backend: false
      surface_cfg:
        inside_out: true # !!! For indoor dataset
        bounding_size: ${bounding_size}
        clip_level_grad_ema_factor: 0
        encoding_cfg:
          # lotd_cfg:
          #   lod_res:     [16,    23,    31,    43,    59,    81,   112,  154,  213,  295,  407,  562,  777,  1073, 1483, 2048]
          #   lod_n_feats: [2,     2,     2,     2,     2,     2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2]
          #   lod_types:   [Dense, Dense, Dense, Dense, Dense, Hash, Hash, Hash, Hash, Hash, Hash, Hash, Hash, Hash, Hash, Hash]
          #   hashmap_size: 524288
          lotd_auto_compute_cfg:
            type: gen_ngp
            min_res: 16
            n_feats: 2
            log2_hashmap_size: 19
            per_level_scale: 1.382
            num_levels: 16
          anneal_cfg:
            type: hardmask
            start_it: ${start_it}
            start_level: ${start_level} # (need to be small: so the training is stable; not too small, so there's still valid initialize pretraining.)
            stop_it: ${stop_it} # Not for too much iters; should end very soon to not hinder quality
          param_init_cfg:
            type: uniform_to_type
            bound: 1.0e-4
          clip_level_grad_ema_factor: 0
        decoder_cfg: 
          # type: linear
          type: mlp
          D: 1
          W: 64
          activation:
            type: softplus
            beta: 100.0
        n_extra_feat_from_output: 0
        radius_init: ${radius_init}
        geo_init_method: pretrain_after_zero_out
        # geo_init_method: pretrain
      radiance_cfg:
        use_pos: true
        use_nablas: true
        use_view_dirs: true
        dir_embed_cfg: 
          type: spherical
          degree: 4
        # use_pos: true
        # use_view_dirs: false
        D: 2
        W: 64
        n_appear_embedding: ${image_embedding_dim}
      # shrink_milestones: [5000]
      accel_cfg:
        type: occ_grid
        resolution: [64,64,64]
        occ_val_fn_cfg:
          type: sdf
          inv_s: 256.0 # => +- 0.01 sdf @ 0.3 thre
        occ_thre: 0.3
        ema_decay: 0.95
        init_cfg:
          mode: from_net
          num_steps: 4
          num_pts: ${eval:"2**20"}
        update_from_net_cfg:
          num_steps: 4
          num_pts: ${eval:"2**20"}
        update_from_samples_cfg: {}
        n_steps_between_update: 16
        n_steps_warmup: 256
      ray_query_cfg:
        query_mode: march_occ_multi_upsample_compressed
        query_param:
          nablas_has_grad: true
          num_coarse: ${num_coarse}
          num_fine: ${num_fine}
          coarse_step_cfg:
            step_mode: linear
          march_cfg:
            step_size: ${step_size}
            max_steps: 4096
          upsample_inv_s: ${upsample_inv_s} 
          upsample_inv_s_factors: ${upsample_inv_s_factors}
          upsample_use_estimate_alpha: true
    asset_params:
      initialize_cfg: 
        lr: 1.0e-3
        num_iters: 500
      training_cfg:
        lr: ${fglr}
        eps: 1.0e-15
        betas: [0.9, 0.99]
        invs_betas: [0.9, 0.999]
        scheduler: ${training.scheduler}
  ImageEmbeddings:
    model_class: app.models.scene.ImageEmbeddings
    model_params:
      dims: ${image_embedding_dim}
      weight_init: uniform
      weight_init_std: 1.0e-4
    training_cfg:
      lr: ${emblr}
      scheduler: ${training.scheduler}

renderer:
  common:
    with_env: true
    with_rgb: true
    with_normal: true
    near: ${near}
    far: ${far}
  train:
    depth_use_normalized_vw: false # For meaningful depth supervision (if any)
    perturb: true
  val:
    depth_use_normalized_vw: true # For correct depth rendering
    perturb: false
    rayschunk: 4096

training:
  #---------- Dataset and sampling
  dataloader:
    preload: true
    preload_on_gpu: true
    tags:
      camera:
        downscale: 1
        list: ${scenebank_cfg.observer_cfgs.Camera.list}
      # image_occupancy_mask: {}
      # image_ignore_mask:
      #   ignore_not_occupied: true
      image_mono_depth: {}
      image_mono_normals: {}
    pixel_dataset:
      #---------- Frame and pixel dataloader
      # joint: false
      # equal_mode: ray_batch
      # num_rays: ${num_rays}
      # frame_sample_mode: uniform
      # pixel_sample_mode: error_map
      #---------- Joint frame-pixel dataloader
      joint: true
      equal_mode: ray_batch
      num_rays: ${num_rays}
    image_patch_dataset:
      num_rays: ${eval:"64*64"}
      random_shift: true
      random_scale: false
      scale: 1.0
      camera_sample_mode: uniform
      frame_sample_mode: uniform

  val_dataloader:
    preload: false
    tags:
      camera:
        downscale: 1
        list: ${scenebank_cfg.observer_cfgs.Camera.list}
      # image_occupancy_mask: {}
      # image_ignore_mask:
      #   ignore_not_occupied: true
      image_mono_depth: {}
      image_mono_normals: {}
    image_dataset:
      camera_sample_mode: uniform
      frame_sample_mode: uniform

  error_map:
    error_map_hw: [32,64]
    frac_uniform: 0.5
    frac_mask_err: 0
    n_steps_max: 2500 # NOTE: The actual effective time of this number now needs to be multiplied by the number of cameras! (Because each iteration samples a camera uniformly at random)

  #---------- Training losses
  uniform_sample: 
    Main: ${eval:"2**12"} # 4 Ki
  losses:
    rgb: 
      fn_type: ${rgb_fn_type}
    mono_depth:
      fn_type: ${mono_fn}
      w: ${mono_w}
      w_grad_reg: ${mono_w_reg}
      gt_pre_scale: 50.0
      gt_pre_shift: 1.0
      ignore_mask_list: []
      mask_pred_thresh: 0.5
      mask_erode: ${mono_erode}
      enable_after: ${mono_after}
      detach_scale_shift: false
      scale_gt_to_pred: false
    mono_normals:
      w_l1: ${w_mono_normal_l1}
      w_cos: ${w_mono_normal_cos}
      ignore_mask_list: []
      apply_in_pixel_train_step: true
    occupancy_mask:
      w: ${w_mask}
      pred_clip: 0
      safe_bce: true
      special_mask_mode: always_occupied # !!! indoor dataset
    eikonal:
      safe_mse: true
      safe_mse_err_limit: 10
      on_occ_ratio: ${on_occ_ratio}
      on_render_type: ${on_render_type}
      on_render_ratio: ${on_render_ratio}
      alpha_reg_zero: 0
      class_name_cfgs:
        Main:
          w: ${w_eikonal}
    sparsity:
      enable_after: ${sparsity_enable_after}
      class_name_cfgs:
        Main:
          type: normalized_logistic_density
          inv_scale: 16.0
          key: sdf
          w: ${w_sparsity} # 1.0e-3
    clearance:
      class_name_cfgs:
        Main:
          w: 0.2
          beta: 10.0
          thresh: 0
    weight_reg:
      class_name_cfgs:
        Main:
          norm_type: 2.0
          w: 1.0e-6
  # clip_grad_val: 
  #   Main:
  #     implicit_surface\.encoding: 0.001
  num_iters: ${num_iters}
  scheduler:
    #---------- exponential
    type: exponential
    num_iters: ${training.num_iters}
    min_factor: ${min_factor}
    warmup_steps: ${warmup_steps}
    #---------- cosine
    # type: warmup_cosine
    # num_iters: ${training.num_iters}
    # min_factor: ${min_factor}
    # warmup_steps: ${warmup_steps}
    #---------- milestone
    # type: multistep
    # milestones: [20000, 30000]
    # gamma: 0.33

  #---------- Logging and validation
  i_val: 1500      # unit: iters
  i_backup: -1 # unit: iters
  i_save: 900     # unit: seconds
  i_log: 20
  log_grad: false
  log_param: false

  ckpt_file: null
  ckpt_ignore_keys: []
  ckpt_only_use_keys: null