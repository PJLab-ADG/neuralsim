#------------------------------------------------------------
#------------    Some shortcut configs
#------------------------------------------------------------

near: 0.01 # > 0 to avoid potential near artifacts
far: null # Far is already constraint by Object's bounding_size when ray_test()
depth_max: 5.0 # To visualize / colorize depth
step_size: 0.005 # Typical value: far / 4000 for single scene
num_coarse: 64
upsample_inv_s: 64.0
# upsample_inv_s_factors: [1, 4]
upsample_inv_s_factors: [1, 4, 16]
num_fine: [8, 8, 32]
radius_scale_min: 1 # Nearest sampling shell of NeRF++ background (Distant-view model)
radius_scale_max: 1000 # Furthest sampling shell of NeRF++ background (Distant-view model)
bgsample: 64

num_rays: 4096

rgb_fn_type: mse

w_sparsity: 1.0e-3
sparsity_enable_after: 0

w_eikonal: 1.0e-3
on_occ_ratio: 1.0
on_render_type: both
on_render_ratio: 0.1

w_mask_entropy: 3.0e-3
mask_entropy_mode: crisp_cr # cross_cr_detached_on_dv, nop
mask_reg_enable_after: 0
mask_reg_anneal_for: 100

num_iters: 7500
warmup_steps: 1000
min_factor: 0.06
degree: 4
fglr: 1.0e-2
bglr: 1.0e-2
emblr: 2.0e-2
bounding_size: 2.0
image_embedding_dim: 4

radius_init: 0.5

start_it: 0
start_level: 2
bg_start_level: -1
stop_it: 1000
bg_stop_it: 100

final_inv_s: 2000.0
ln_inv_s_init: 0.1
ctrl_start_it: 2000

#------------------------------------------------------------
#------------    Full configs
#------------------------------------------------------------
exp_dir: ./logs/bmvs/permuto_neus.${bmvs_id}


bmvs_id: 5c0d13b795da9479e12e2ee9
# bmvs_id: 5aa515e613d42d091d29d300
# bmvs_id: 5a4a38dad38c8a075495b5d2
# bmvs_id: 5a618c72784780334bc1972d
# bmvs_id: 5a8315f624b8e938486e0bd8
dataset_cfg:
  target: dataio.bmvs.BMVSDataset
  param: # Trainval dataset_impl
    root: /data1/bmvs
    # root: /home/ventus/datasets/neus
    instance_id: ${bmvs_id}
    cam_file: 'cameras_sphere.npz'

# bmvs_id: bmvs_dog # 
# dataset_cfg:
#   target: dataio.dtu.DTUDataset
#   param: # Trainval dataset_impl
#     root: /data1/neus
#     # root: /home/ventus/datasets/neus
#     instance_id: ${bmvs_id}
#     cam_file: 'cameras_sphere.npz'

scenebank_cfg:
  scenarios:
    - ${bmvs_id}
  observer_cfgs: 
    Camera:
      list: [camera]

assetbank_cfg:
  Main:
    model_class: app.models.single.PermutoNeuSObj
    model_params:
      dtype: half
      var_ctrl_cfg:
        ln_inv_s_init: ${ln_inv_s_init}
        ln_inv_s_factor: 10.0
        ctrl_type: mix_linear
        start_it: ${ctrl_start_it}
        stop_it: ${training.num_iters}
        final_inv_s: ${final_inv_s}
      cos_anneal_cfg: null
      use_tcnn_backend: false
      surface_cfg:
        bounding_size: ${bounding_size}
        clip_level_grad_ema_factor: 0
        encoding_cfg:
          permuto_auto_compute_cfg:
            type: multi_res
            coarsest_res: 10.0
            finest_res: 2000.0
            n_levels: 16
            n_feats: 2
            log2_hashmap_size: 19
            apply_random_shifts_per_level: true
          anneal_cfg:
            type: hardmask
            start_it: ${start_it}
            start_level: ${start_level} # (need to be small: so the training is stable; not too small, so there's still valid initialize pretraining.)
            stop_it: ${stop_it} # Not for too much iters; should end very soon to not hinder quality
          param_init_cfg:
            type: uniform
            bound: 1.0e-4
          clip_level_grad_ema_factor: 0
        decoder_cfg: 
          # type: linear
          type: mlp
          D: 1
          W: 64
          # select_n_levels: 14
          activation:
            type: softplus
            beta: 100.0
        n_extra_feat_from_output: 0
        radius_init: ${radius_init}
        geo_init_method: pretrain_after_zero_out
        # geo_init_method: pretrain
      radiance_cfg:
        use_pos: true
        use_nablas: true
        use_view_dirs: true
        dir_embed_cfg: 
          type: spherical
          degree: ${degree}
        # use_pos: true
        # use_view_dirs: false
        D: 2
        W: 64
        n_appear_embedding: ${image_embedding_dim}
      # shrink_milestones: [5000]
      accel_cfg:
        type: occ_grid
        resolution: [64,64,64]
        occ_val_fn_cfg:
          type: sdf
          inv_s: 256.0 # => +- 0.01 sdf @ 0.3 thre
        occ_thre: 0.3
        ema_decay: 0.95
        init_cfg:
          mode: from_net
          num_steps: 4
          num_pts: ${eval:"2**20"}
        update_from_net_cfg:
          num_steps: 4
          num_pts: ${eval:"2**20"}
        update_from_samples_cfg: {}
        n_steps_between_update: 16
        n_steps_warmup: 256
      ray_query_cfg:
        query_mode: march_occ_multi_upsample_compressed
        # query_mode: march_occ_multi_upsample
        query_param:
          nablas_has_grad: true
          num_coarse: ${num_coarse}
          num_fine: ${num_fine}
          coarse_step_cfg:
            step_mode: linear
          march_cfg:
            step_size: ${step_size}
            max_steps: 4096
          upsample_inv_s: ${upsample_inv_s} 
          upsample_inv_s_factors: ${upsample_inv_s_factors}
          upsample_use_estimate_alpha: true
    asset_params:
      initialize_cfg: 
        lr: 1.0e-3
        num_iters: 500
      training_cfg:
        lr: ${fglr}
        eps: 1.0e-15
        betas: [0.9, 0.99]
        invs_betas: [0.9, 0.999]
        scheduler: ${training.scheduler}
  Distant:
    model_class: app.models.single.PermutoNeRFDistant
    model_params:
      dtype: half
      encoding_cfg:
        input_ch: 4
        permuto_auto_compute_cfg:
          type: multi_res
          coarsest_res: 10.0
          finest_res: 2000.0
          n_levels: 16
          n_feats: 2
          log2_hashmap_size: 19
        param_init_cfg:
          type: uniform
          bound: 1.0e-4
        anneal_cfg:
          type: hardmask
          start_it: ${start_it}
          start_level: ${bg_start_level} # (need to be small: so the training is stable; not too small, so there's still valid initialize pretraining.)
          stop_it: ${bg_stop_it} # Not for too much iters; should end very soon to not hinder quality
      extra_pos_embed_cfg:
        type: identity
      density_decoder_cfg: 
        type: mlp
        D: 1
        W: 64
        output_activation: softplus
      radiance_decoder_cfg:
        use_pos: false
        # pos_embed_cfg:
        #   type: identity
        use_view_dirs: true
        dir_embed_cfg:
          type: spherical
          degree: 4
        use_nablas: false
        D: 2
        W: 64
        n_appear_embedding: ${image_embedding_dim}
      n_extra_feat_from_output: 0
      use_tcnn_backend: false
      include_inf_distance: true
      radius_scale_min: ${radius_scale_min}
      radius_scale_max: ${radius_scale_max}
      ray_query_cfg:
        query_mode: march
        query_param:
          march_cfg:
            sample_mode: box
            max_steps: ${bgsample}
    asset_params:
      populate_cfg:
        cr_obj_classname: Main
      training_cfg:
        lr: ${bglr}
        eps: 1.0e-15
        betas: [0.9, 0.99]
        scheduler: ${training.scheduler}
  ImageEmbeddings:
    model_class: app.models.scene.ImageEmbeddings
    model_params:
      dims: ${image_embedding_dim}
      weight_init: uniform
      weight_init_std: 1.0e-4
    training_cfg:
      lr: ${emblr}
      scheduler: ${training.scheduler}

renderer:
  common:
    with_env: true
    with_rgb: true
    with_normal: true
    near: ${near}
    far: ${far}
  train:
    depth_use_normalized_vw: false # For meaningful depth supervision (if any)
    perturb: true
  val:
    depth_use_normalized_vw: true # For correct depth rendering
    perturb: false
    rayschunk: 4096

training:
  #---------- Dataset and sampling
  dataloader:
    preload: true
    preload_on_gpu: true
    tags:
      camera:
        downscale: 1
        list: ${scenebank_cfg.observer_cfgs.Camera.list}
      # image_occupancy_mask: {}
      # image_ignore_mask:
      #   ignore_not_occupied: true
    pixel_dataset:
      #---------- Frame and pixel dataloader
      # joint: false
      # equal_mode: ray_batch
      # num_rays: ${num_rays}
      # frame_sample_mode: uniform
      # pixel_sample_mode: error_map
      #---------- Joint frame-pixel dataloader
      joint: true
      equal_mode: ray_batch
      num_rays: ${num_rays}
  val_dataloader:
    preload: false
    tags:
      camera:
        downscale: 4
        list: ${scenebank_cfg.observer_cfgs.Camera.list}
      # image_occupancy_mask: {}
      # image_ignore_mask:
      #   ignore_not_occupied: true
    image_dataset:
      camera_sample_mode: uniform
      frame_sample_mode: uniform

  error_map:
    error_map_hw: [32,64]
    frac_uniform: 0.5
    frac_mask_err: 0
    n_steps_max: 2500 # NOTE: The actual effective time of this number now needs to be multiplied by the number of cameras! (Because each iteration samples a camera uniformly at random)

  #---------- Training losses
  uniform_sample:
    Main: ${eval:"2**12"} # 4 Ki
  losses:
    rgb: 
      fn_type: ${rgb_fn_type}
    # occupancy_mask:
    #   w: ${w_mask}
    #   w_on_errmap: ${w_mask_err}
    #   safe_bce: ${safe_bce}
    #   pred_clip: ${pred_clip}
    mask_entropy:
      w: ${w_mask_entropy}
      mode: ${mask_entropy_mode}
      enable_after: ${mask_reg_enable_after}
      anneal:
        type: linear
        start_it: ${mask_reg_enable_after}
        stop_it: ${eval:"${mask_reg_enable_after}+${mask_reg_anneal_for}"}
        start_val: 0
        stop_val: ${w_mask_entropy}
        update_every: 100
    eikonal:
      safe_mse: true
      safe_mse_err_limit: 10
      on_occ_ratio: ${on_occ_ratio}
      on_render_type: ${on_render_type}
      on_render_ratio: ${on_render_ratio}
      alpha_reg_zero: 0
      class_name_cfgs:
        Main:
          w: ${w_eikonal}
    sparsity:
      enable_after: ${sparsity_enable_after}
      class_name_cfgs:
        Main:
          type: normalized_logistic_density
          inv_scale: 16.0
          key: sdf
          w: ${w_sparsity} # 1.0e-3
    clearance:
      class_name_cfgs:
        Main:
          w: 0.2
          beta: 10.0
          thresh: 0
    weight_reg:
      class_name_cfgs:
        Main:
          norm_type: 2.0
          w: 1.0e-6
        Distant:
          norm_type: 2.0
          w: 1.0e-6

  # clip_grad_val: 
  #   Main:
  #     implicit_surface\.encoding: 0.001
  num_iters: ${num_iters}
  scheduler:
    #---------- exponential
    type: exponential
    num_iters: ${training.num_iters}
    min_factor: ${min_factor}
    warmup_steps: ${warmup_steps}
    #---------- cosine
    # type: warmup_cosine
    # num_iters: ${training.num_iters}
    # min_factor: ${min_factor}
    # warmup_steps: ${warmup_steps}
    #---------- milestone
    # type: multistep
    # milestones: [20000, 30000]
    # gamma: 0.33

  #---------- Logging and validation
  i_val: 1500      # unit: iters
  i_backup: -1 # unit: iters
  i_save: 900     # unit: seconds
  i_log: 20
  log_grad: false
  log_param: false

  ckpt_file: null
  ckpt_ignore_keys: []
  ckpt_only_use_keys: null