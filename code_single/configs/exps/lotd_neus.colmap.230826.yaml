#------------------------------------------------------------
#------------    Some shortcut configs
#------------------------------------------------------------

near: 0.01 # > 0 to avoid potential near artifacts
far: null # Far is already constraint by Object's bounding_size when ray_test()
depth_max: 5.0 # To visualize / colorize depth
step_size: 0.005 # Typical value: far / 4000 for single scene
num_coarse: 64
upsample_inv_s: 64.0
# upsample_inv_s_factors: [1, 4]
upsample_inv_s_factors: [1, 4, 16]
num_fine: [8, 8, 32]
radius_scale_min: 1 # Nearest sampling shell of NeRF++ background (Distant-view model)
radius_scale_max: 20 # Furthest sampling shell of NeRF++ background (Distant-view model)

bgsample: 64
bg_param_mi: 8

num_rays: 4096

rgb_fn_type: mse

w_sparsity: 1.0e-3
sparsity_enable_after: 0

w_eikonal: 1.0e-3
on_occ_ratio: 1.0
on_render_type: both
on_render_ratio: 0.1

w_mask_entropy: 3.0e-3
mask_entropy_mode: crisp_cr # cross_cr_detached_on_dv, nop
mask_reg_enable_after: 0
mask_reg_anneal_for: 100

num_iters: 7500
warmup_steps: 1000
min_factor: 0.06
degree: 4
fglr: 1.0e-2
bglr: 1.0e-2
emblr: 2.0e-2
bounding_size: 2.0
image_embedding_dim: 4

radius_init: 0.5

start_it: 0
start_level: 2
bg_start_level: -1
stop_it: 1000
bg_stop_it: 100

final_inv_s: 2400.0
ln_inv_s_init: 0.1
ctrl_start_it: 2000

#------------------------------------------------------------
#------------    Full configs
#------------------------------------------------------------
instance_id: bicycle # 14,8,0
# instance_id: stump # 4,2,0
# instance_id: garden # 16,12,8

exp_dir: ./logs/colmap/instant_neus_${instance_id}_bg${bg_param_mi}M_bgsample=${bgsample}_bgsmax=${radius_scale_max}

dataset_cfg:
  target: dataio.colmap.COLMAPDataset
  param:
    data_dir: /data1/360_v2/${instance_id}
    image_dirname: images_4
    downscale: 4
    estimate_focus_center: solve
    normalize_scale: max
    normalize_scale_factor: 1.1

scenebank_cfg:
  scenarios: [object]
  observer_cfgs: 
    Camera:
      list: [camera]

assetbank_cfg:
  Main:
    model_class: app.models.single.LoTDNeuSObj
    model_params:
      dtype: half
      var_ctrl_cfg:
        ln_inv_s_init: ${ln_inv_s_init}
        ln_inv_s_factor: 10.0
        ctrl_type: mix_linear
        start_it: ${ctrl_start_it}
        stop_it: ${training.num_iters}
        final_inv_s: ${final_inv_s}
      cos_anneal_cfg: null
      use_tcnn_backend: false
      surface_cfg:
        bounding_size: ${bounding_size}
        clip_level_grad_ema_factor: 0
        encoding_cfg:
          # lotd_cfg:
          #   lod_res:     [16,    23,    31,    43,    59,    81,   112,  154,  213,  295,  407,  562,  777,  1073, 1483, 2048]
          #   lod_n_feats: [2,     2,     2,     2,     2,     2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2]
          #   lod_types:   [Dense, Dense, Dense, Dense, Dense, Hash, Hash, Hash, Hash, Hash, Hash, Hash, Hash, Hash, Hash, Hash]
          #   hashmap_size: 524288
          lotd_auto_compute_cfg:
            type: gen_ngp
            min_res: 16
            n_feats: 2
            log2_hashmap_size: 19
            per_level_scale: 1.382
            num_levels: 16
          anneal_cfg:
            type: hardmask
            start_it: ${start_it}
            start_level: ${start_level} # (need to be small: so the training is stable; not too small, so there's still valid initialize pretraining.)
            stop_it: ${stop_it} # Not for too much iters; should end very soon to not hinder quality
          param_init_cfg:
            method: uniform_to_type
            bound: 1.0e-4
          clip_level_grad_ema_factor: 0
        decoder_cfg: 
          # type: linear
          type: mlp
          D: 1
          W: 64
          # select_n_levels: 14
          activation:
            type: softplus
            beta: 100.0
        n_rgb_used_output: 0
        radius_init: ${radius_init}
        geo_init_method: pretrain_after_zero_out
        # geo_init_method: pretrain
      radiance_cfg:
        use_pos: true
        use_nablas: true
        use_view_dirs: true
        dir_embed_cfg: 
          type: spherical
          degree: ${degree}
        # use_pos: true
        # use_view_dirs: false
        D: 2
        W: 64
        n_appear_embedding: ${image_embedding_dim}
      # shrink_milestones: [5000]
      accel_cfg:
        type: occ_grid
        resolution: [64,64,64]
        occ_val_fn_cfg:
          type: sdf
          inv_s: 256.0 # => +- 0.01 sdf @ 0.3 thre
        occ_thre: 0.3
        ema_decay: 0.95
        init_cfg:
          mode: from_net
          num_steps: 4
          num_pts: ${eval:"2**20"}
        acquire_from_net_cfg:
          num_steps: 4
          num_pts: ${eval:"2**20"}
        acquire_from_samples_cfg: {}
        n_steps_between_update: 16
        n_steps_warmup: 256
      ray_query_cfg:
        query_mode: march_occ_multi_upsample_compressed
        # query_mode: march_occ_multi_upsample
        query_param:
          nablas_has_grad: true
          num_coarse: ${num_coarse}
          num_fine: ${num_fine}
          coarse_step_cfg:
            step_mode: linear
          march_cfg:
            step_size: ${step_size}
            max_steps: 4096
          upsample_inv_s: ${upsample_inv_s} 
          upsample_inv_s_factors: ${upsample_inv_s_factors}
          upsample_use_estimate_alpha: true
    asset_params:
      initialize_cfg: 
        lr: 1.0e-3
        num_iters: 500
  Distant:
    model_class: app.models.single.LoTDNeRFDistant
    model_params:
      dtype: half
      encoding_cfg:
        input_ch: 4
        lotd_use_cuboid: true
        lotd_auto_compute_cfg:
          type: ngp4d
          target_num_params: ${eval:"${bg_param_mi}*(2**20)"} # 16 Mi params
          min_res_xyz: 8
          min_res_w: 4
          n_feats: 2
          log2_hashmap_size: 19
          per_level_scale: 1.382
        # lotd_auto_compute_cfg:
        #   type: ngp4d
        #   target_num_params: ${eval:"16*(2**20)"} # 16 Mi params
        #   min_res_xyz: 16
        #   min_res_w: 4
        #   n_feats: 2
        #   log2_hashmap_size: 20
        #   per_level_scale: 1.382
        param_init_cfg:
          method: uniform_to_type
          bound: 1.0e-4
        anneal_cfg:
          type: hardmask
          start_it: ${start_it}
          start_level: ${bg_start_level} # (need to be small: so the training is stable; not too small, so there's still valid initialize pretraining.)
          stop_it: ${bg_stop_it} # Not for too much iters; should end very soon to not hinder quality
      extra_pos_embed_cfg:
        type: identity
      sigma_decoder_cfg: 
        type: mlp
        D: 1
        W: 64
        output_activation: softplus
      radiance_decoder_cfg:
        use_pos: false
        # pos_embed_cfg:
        #   type: identity
        use_view_dirs: true
        dir_embed_cfg:
          type: spherical
          degree: 4
        use_nablas: false
        D: 2
        W: 64
        n_appear_embedding: ${image_embedding_dim}
      n_rgb_used_output: 0
      use_tcnn_backend: false
      include_inf_distance: true
      radius_scale_min: ${radius_scale_min}
      radius_scale_max: ${radius_scale_max}
      ray_query_cfg:
        query_mode: march_occ
        query_param:
          march_cfg:
            sample_mode: box
            max_steps: ${bgsample}
    asset_params:
      populate_cfg:
        cr_obj_classname: Main
  ImageEmbeddings:
    model_class: app.models.scene.ImageEmbeddings
    model_params:
      dims: ${image_embedding_dim}
      weight_init: uniform
      weight_init_std: 1.0e-4

renderer:
  common:
    with_env: true
    with_rgb: true
    with_normal: true
    near: ${near}
    far: ${far}
  train:
    depth_use_normalized_vw: false # For meaningful depth supervision (if any)
    perturb: true
  val:
    depth_use_normalized_vw: true # For correct depth rendering
    perturb: false
    rayschunk: 4096

training:
  #---------- Dataset and sampling
  dataloader:
    preload: true
    preload_on_gpu: true
    tags:
      camera:
        downscale: 1
        list: ${scenebank_cfg.observer_cfgs.Camera.list}
      # rgb_mask: {}
      # rgb_ignore_mask:
      #   ignore_not_occupied: true
    pixel_dataset:
      #---------- Frame and pixel dataloader
      # joint: false
      # equal_mode: ray_batch
      # num_rays: ${num_rays}
      # frame_sample_mode: uniform
      # pixel_sample_mode: error_map
      # error_map_res: [32,32]
      # uniform_sampling_fraction: 0.5
      #---------- Joint frame-pixel dataloader
      joint: true
      equal_mode: ray_batch
      num_rays: ${num_rays}
      error_map_res: [32,32]
      uniform_sampling_fraction: 0.5
      respect_errormap_after: 0
  val_dataloader:
    preload: false
    tags:
      camera:
        downscale: 4
        list: ${scenebank_cfg.observer_cfgs.Camera.list}
      # rgb_mask: {}
      # rgb_ignore_mask:
      #   ignore_not_occupied: true
    image_dataset:
      camera_sample_mode: uniform
      frame_sample_mode: uniform

  #---------- Training losses
  uniform_sample: ${eval:"2**12"} # 4 Ki
  losses:
    rgb: 
      fn_type: ${rgb_fn_type}
    # occupancy_mask:
    #   w: ${w_mask}
    #   w_on_errmap: ${w_mask_err}
    #   safe_bce: ${safe_bce}
    #   pred_clip: ${pred_clip}
    mask_entropy:
      w: ${w_mask_entropy}
      mode: ${mask_entropy_mode}
      enable_after: ${mask_reg_enable_after}
      anneal:
        type: linear
        start_it: ${mask_reg_enable_after}
        stop_it: ${eval:"${mask_reg_enable_after}+${mask_reg_anneal_for}"}
        start_val: 0
        stop_val: ${w_mask_entropy}
        update_every: 100
    eikonal:
      safe_mse: true
      safe_mse_err_limit: 10
      on_occ_ratio: ${on_occ_ratio}
      on_render_type: ${on_render_type}
      on_render_ratio: ${on_render_ratio}
      alpha_reg_zero: 0
      class_name_cfgs:
        Main:
          w: ${w_eikonal}
    sparsity:
      enable_after: ${sparsity_enable_after}
      class_name_cfgs:
        Main:
          type: normalized_logistic_density
          inv_scale: 16.0
          key: sdf
          w: ${w_sparsity} # 1.0e-3
    clearance:
      class_name_cfgs:
        Main:
          w: 0.2
          beta: 10.0
          thresh: 0
    weight_reg:
      class_name_cfgs:
        Main:
          norm_type: 2.0
          w: 1.0e-6
        Distant:
          norm_type: 2.0
          w: 1.0e-6

  #---------- Optimization and shedulers
  optim:
    default:  1.0e-4
    Main: 
      lr: ${fglr}
      eps: 1.0e-15
      betas: [0.9, 0.99]
      invs_betas: [0.9, 0.999]
    Distant: 
      lr: ${bglr}
      eps: 1.0e-15
      betas: [0.9, 0.99]
    ImageEmbeddings: ${emblr}
  # clip_grad_val: 
  #   Main:
  #     implicit_surface\.encoding: 0.001
  num_iters: ${num_iters}
  scheduler:
    #---------- exponential
    type: exponential_step
    num_iters: ${training.num_iters}
    min_factor: ${min_factor}
    warmup_steps: ${warmup_steps}
    #---------- cosine
    # type: warmupcosine
    # num_iters: ${training.num_iters}
    # min_factor: ${min_factor}
    # warmup_steps: ${warmup_steps}
    #---------- milestone
    # type: multistep
    # milestones: [20000, 30000]
    # gamma: 0.33

  #---------- Logging and validation
  i_val: 1500      # unit: iters
  i_backup: -1 # unit: iters
  i_save: 900     # unit: seconds
  i_log: 20
  log_grad: false
  log_param: false

  ckpt_file: null
  ckpt_ignore_keys: []
  ckpt_only_use_keys: null